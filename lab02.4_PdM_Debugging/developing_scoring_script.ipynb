{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Updating a Docker Image before Deployment as a Webservice\n",
    "\n",
    "This notebook demonstrates how to make changes to an existing docker image, before deploying it as a webservice.  \n",
    "\n",
    "Knowing how to do this can be helpful, for example if you need to debug the execution script of a webservice you're developing, and debugging it involves several iterations of code changes.  In this case it is not an option to deploy your application as a webservice at every iteration, because the time it takes to deploy your service will significantly slow you down.  In some cases, it may be easier to simply run the execution script on the command line, but this not an option if your script accumulates data across individual calls.\n",
    "\n",
    "**Note:** This code was tested on a Data Science Virtual Machine ([DSVM](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/)), running Ubuntu Linux 16.04 (Xenial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your Azure Workspace\n",
    "\n",
    "We need to set up your workspace, and make sure we have access to it from here.\n",
    "\n",
    "This requires that you have downloaded the ***config.json*** configuration file for your azure workspace.\n",
    "\n",
    "Follow this [Quickstart](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-get-started) to set up your workspace and to download the config.json file, which contains information about the workspace you just created. Save the file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that you have the correction version of the Azure ML SDK installed on your workstation or VM.  If you don't have the write version, please follow these [Installation Instructions](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python#install-the-sdk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "check version"
    ]
   },
   "outputs": [],
   "source": [
    "import azureml\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "\n",
    "if azureml.core.VERSION == '0.1.59':\n",
    "    print(\"Looks like you have the correct version. We are good to go.\")\n",
    "else:\n",
    "    print(\"There is a version mismatch, this notebook may not work as expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Docker image using the Azure ML SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a template execution script for your application\n",
    "\n",
    "We are going to start with just an execution script for your webservice that ingests one value at a time and returns a running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json # we use json in order to interact with the anomaly detection service via a RESTful API\n",
    "\n",
    "# The init function is only run once, when the webservice (or Docker container) is started\n",
    "def init():\n",
    "    global running_avg, curr_n\n",
    "    \n",
    "    running_avg = 0.0\n",
    "    curr_n = 0\n",
    "    \n",
    "    pass\n",
    "\n",
    "# the run function is run everytime we interact with the service\n",
    "def run(raw_data):\n",
    "    \"\"\"\n",
    "    Calculates rolling average according to Welford's online algorithm.\n",
    "    https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online\n",
    "\n",
    "    :param raw_data: raw_data should be a json query containing a dictionary with the key 'value'\n",
    "    :return: runnin_avg (float, json response)\n",
    "    \"\"\"\n",
    "    global running_avg, curr_n\n",
    "    \n",
    "    value = json.loads(raw_data)['value']\n",
    "    n_arg = 5 # we calculate the average over the last \"n\" measures\n",
    "    \n",
    "    curr_n += 1\n",
    "    n = min(curr_n, n_arg) # in case we don't have \"n\" measures yet\n",
    "    \n",
    "    running_avg += (value - running_avg) / n\n",
    "    \n",
    "    return json.dumps(running_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment file for your Conda environment\n",
    "\n",
    "Next, create an environment file (environment.yml) that specifies all the python dependencies of your script. This file is used to ensure that all of those dependencies are installed in the Docker image.  Let's assume your Webservice will require ``azureml-sdk``, ``scikit-learn``, and ``pynacl``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "set conda dependencies"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_pip_package(\"pynacl==1.2.1\")\n",
    "\n",
    "with open(\"environment.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of the `environment.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"environment.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the initial Docker image\n",
    "\n",
    "We use the ``environment.yml`` and ``score.py`` files from above, to create an initial Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\", \n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"environment.yml\")\n",
    "\n",
    "# create the docker image. this should take less than 5 minutes\n",
    "image = ContainerImage.create(name = \"my-docker-image\",\n",
    "                              image_config = image_config,\n",
    "                              models = [],\n",
    "                              workspace = ws)\n",
    "\n",
    "# we wait until the image has been created\n",
    "image.wait_for_creation(show_output=True)\n",
    "\n",
    "# let's save the image location\n",
    "imageLocation = image.serialize()['imageLocation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the application by running the Docker container locally\n",
    "\n",
    "### Download the created Docker image from the Azure Container Registry ([ACR](https://azure.microsoft.com/en-us/services/container-registry/))\n",
    "\n",
    "Here we use some [cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) to exchange variables between python and bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$imageLocation\" \n",
    "\n",
    "# get the location of the docker image in ACR\n",
    "imageLocation=$1\n",
    "\n",
    "# extract the address of the repository within ACR\n",
    "repository=$(echo $imageLocation | cut -f 1 -d \".\")\n",
    "\n",
    "echo \"Attempting to login to repository $repository\"\n",
    "az acr login --name $repository\n",
    "echo\n",
    "\n",
    "echo \"Trying to pull image $imageLocation\"\n",
    "docker pull $imageLocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the docker container\n",
    "\n",
    "We use standard Docker commands to start the container locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$imageLocation\"\n",
    "\n",
    "# extract image name and tag from imageLocation\n",
    "image_name=$(echo $1 | cut -f 1 -d \":\")\n",
    "tag=$(echo $1 | cut -f 2 -d \":\")\n",
    "echo \"Image name: $image_name, tag: $tag\"\n",
    "\n",
    "# extract image ID from list of downloaded docker images\n",
    "image_id=$(docker images $image_name:$tag --format \"{{.ID}}\"))\n",
    "echo \"Image ID: $image_id\"\n",
    "\n",
    "# we forward TCP port 5001 of the docker container to local port 8080 for testing\n",
    "echo \"Starting docker container\"\n",
    "docker run -d -p 8080:5001 $image_id\n",
    "\n",
    "sleep 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the docker container\n",
    "\n",
    "We test the docker container, by sending some data to it to see how it responds - just as we would with a Webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values = np.random.normal(0,1,100)\n",
    "values = np.cumsum(values)\n",
    "\n",
    "\n",
    "running_avgs = []\n",
    "\n",
    "for value in values:\n",
    "    raw_data = {\"value\": value}\n",
    "\n",
    "    r = requests.post('http://localhost:8080/score', json=raw_data)\n",
    "\n",
    "    result = json.loads(r.json())\n",
    "    running_avgs.append(result)\n",
    "\n",
    "plt.plot(values)\n",
    "plt.plot(running_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the container\n",
    "\n",
    "Let's make a change to the the execution script: We want to enable an additional input argument to ``score.py`` to set how many previous values to consider in the running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json # we use json in order to interact with the anomaly detection service via a RESTful API\n",
    "\n",
    "# The init function is only run once, when the webservice (or Docker container) is started\n",
    "def init():\n",
    "    global running_avg, curr_n\n",
    "    \n",
    "    running_avg = 0.0\n",
    "    curr_n = 0\n",
    "    \n",
    "    pass\n",
    "\n",
    "# the run function is run everytime we interact with the service\n",
    "def run(raw_data):\n",
    "    \"\"\"\n",
    "    Calculates rolling average according to Welford's online algorithm.\n",
    "    https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online\n",
    "\n",
    "    :param raw_data: raw_data should be a json query containing a dictionary with the key 'value'\n",
    "    :return: runnin_avg (float, json response)\n",
    "    \"\"\"\n",
    "    global running_avg, curr_n\n",
    "    \n",
    "    value = json.loads(raw_data)['value']\n",
    "    n_arg = json.loads(raw_data)['n'] # we calculate the average over the last \"n\" measures\n",
    "    \n",
    "    curr_n += 1\n",
    "    n = min(curr_n, n_arg) # in case we don't have \"n\" measures yet\n",
    "    \n",
    "    running_avg += (value - running_avg) / n\n",
    "    \n",
    "    return json.dumps(running_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update container image\n",
    "\n",
    "Copy the changed ``score.py`` into the running docker container and commit the changes to the container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $imageLocation\n",
    "\n",
    "image_location=$1\n",
    "\n",
    "# extract image name and tag from imageLocation\n",
    "image_name=$(echo $image_location | cut -f 1 -d \":\")\n",
    "tag=$(echo $image_location | cut -f 2 -d \":\")\n",
    "\n",
    "echo \"Image name: $image_name, tag: $tag\"\n",
    "\n",
    "# extract image id\n",
    "image_id=$(docker images | grep $image_name | grep \" ${tag} \" | cut -b 74-85)\n",
    "\n",
    "echo \"Image ID: $image_id\"\n",
    "\n",
    "# extract container ID\n",
    "container_id=$(docker ps | tail -n1 | cut -f 1 -d \" \")\n",
    "echo \"Container ID: $container_id\"\n",
    "\n",
    "# copy modified scoring script again\n",
    "docker cp score.py $container_id:/var/azureml-app/\n",
    "\n",
    "sleep 1\n",
    "# commit changes made in the container to the local copy of the image\n",
    "docker commit $container_id $image_location\n",
    "\n",
    "# let's wait for two seconds here\n",
    "sleep 1\n",
    "\n",
    "# stop the container\n",
    "docker restart $container_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the container\n",
    "\n",
    "**Note**, you probably have to run the above cell twice for the change to score.py to ahve an effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 2  # set the number of values going into the running avg\n",
    "values = np.random.normal(0,1,100)\n",
    "values = np.cumsum(values)\n",
    "\n",
    "\n",
    "running_avgs = []\n",
    "\n",
    "for value in values:\n",
    "    raw_data = {\"value\": value, \"n\": n}\n",
    "\n",
    "    r = requests.post('http://localhost:8080/score', json=raw_data)\n",
    "\n",
    "    result = json.loads(r.json())\n",
    "    running_avgs.append(result)\n",
    "\n",
    "plt.plot(values)\n",
    "plt.plot(running_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the updated container to ACR\n",
    "\n",
    "**First**, test your Docker container again (run the json query above), to ensure that the changes are having the expected effect. \n",
    "\n",
    "**Then** you can push the image into ACR, so that it can be retrieved by the Azure ML SDK when you want to deploy your Webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$imageLocation\"\n",
    "\n",
    "image_location=$1\n",
    "\n",
    "# extract container ID\n",
    "container_id=$(docker ps | tail -n1 | cut -f 1 -d \" \")\n",
    "echo \"Container ID: $container_id\"\n",
    "\n",
    "sleep 1\n",
    "# commit changes made in the container to the local copy of the image\n",
    "docker commit $container_id $image_location\n",
    "\n",
    "docker push $image_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to deploy the container to ACI, just to make sure everything behaves as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# create configuration for ACI\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"some data\",  \"method\" : \"machine learning\"}, \n",
    "                                               description=\"Does machine learning on some data\")\n",
    "# pull the image\n",
    "image = ContainerImage(ws, name='my-docker-image', tags='1')\n",
    "\n",
    "# deploy webservice\n",
    "service_name = 'my-web-service'\n",
    "service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                            image = image,\n",
    "                                            name = service_name,\n",
    "                                            workspace = ws)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 2  # set the number of values going into the running avg\n",
    "values = np.random.normal(0,1,100)\n",
    "values = np.cumsum(values)\n",
    "\n",
    "\n",
    "running_avgs = []\n",
    "\n",
    "for value in values:\n",
    "    raw_data = json.dumps({\"value\": value, \"n\": n})\n",
    "    raw_data = bytes(raw_data, encoding = 'utf8')\n",
    "    \n",
    "    # predict using the deployed model\n",
    "    result = json.loads(service.run(input_data=raw_data))\n",
    "\n",
    "    running_avgs.append(result)\n",
    "\n",
    "plt.plot(values)\n",
    "plt.plot(running_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "To keep the resource group and workspace for other tutorials and exploration, you can delete only the ACI deployment using this API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "msauthor": "sgilley"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
